{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get libraries\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import time\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "import requests as req\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize splinter\n",
    "executable_path = {'executable_path' : '/Users/Omome/Documents/chromedriver'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NASA Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://mars.nasa.gov/news/\" \n",
    "response = req.get(url)\n",
    "\n",
    "soup = bs(response.text, 'html5lib')\n",
    "\n",
    "news_title = soup.find(\"div\", class_=\"content_title\").text\n",
    "news_p = soup.find(\"div\", class_=\"rollover_description_inner\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(news_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(news_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JPL Mars Spaces Images - Featured Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#URL to be scraped\n",
    "url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Go To Full Image\n",
    "browser.links.find_by_partial_text('FULL IMAGE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Go To More Info\n",
    "browser.links.find_by_partial_text('more info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Beautiful Soup object; parse with HTML Parser\n",
    "html = browser.html\n",
    "soup = bs(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_img_url = soup.find('img', class_='thumb')['src']\n",
    "image_url = \"https://jpl.nasa.gov\" + feat_img_url\n",
    "featured_image_url = image_url\n",
    "print(featured_image_url)\n",
    "\n",
    "#This is the URL\n",
    "#https://jpl.nasa.gov/spaceimages/images/wallpaper/PIA23741-640x350.jpg. #saving for refernce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mars Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the Mars Weather twitter account here and scrape the latest Mars weather tweet from the page. \n",
    "#Save the tweet text for the weather report as a variable called mars_weather."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = 'https://twitter.com/marswxreport?lang=en'\n",
    "#browser.visit(url)\n",
    "\n",
    "\n",
    "twitter_response = req.get(\"https://twitter.com/marswxreport?lang=en\")\n",
    "twitter_soup = bs(twitter_response.text, 'html.parser')\n",
    "\n",
    "tweet_containers = twitter_soup.find_all('div', class_=\"js-tweet-text-container\")\n",
    "\n",
    "mars_weather = tweet_containers[0].text\n",
    "\n",
    "print(mars_weather)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the Mars Facts webpage [here](http://space-facts.com/mars/) and use Pandas to \n",
    "#scrape the table containing facts about the planet including Diameter, Mass, etc.\n",
    "import pandas as pd\n",
    "facts_url = \"https://space-facts.com/mars/\"\n",
    "browser.visit(facts_url)\n",
    "mars_data = pd.read_html(facts_url)\n",
    "mars_data = pd.DataFrame(mars_data[0])\n",
    "mars_facts = mars_data.to_html(header = False, index = False)\n",
    "print(mars_facts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mars Hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit the USGS Astrogeology site [here](https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars) to obtain high resolution images for each of Mar's hemispheres.\n",
    "url4 = \"https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars\"\n",
    "browser.visit(url4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "#Create Beautiful Soup object; parse with HTML Parser\n",
    "html = browser.html\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "hemisphere_data=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the dictionary with the image url string \n",
    "# and the hemisphere title to a list. This list will contain one dictionary for each hemisphere.\n",
    "# looping through each hemisphere image and collecting url and title data\n",
    "for i in range (4):\n",
    "    time.sleep(10)\n",
    "    \n",
    "    images = browser.find_by_tag('h3')\n",
    "    \n",
    "    images[i].click()\n",
    "    \n",
    "    html = browser.html\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    partial = soup.find(\"img\", class_=\"wide-image\")[\"src\"]\n",
    "    image_title = soup.find(\"h2\",class_=\"title\").text\n",
    "    \n",
    "    image_url = 'https://astrogeology.usgs.gov'+ partial\n",
    "    dictionary = {\"title\":image_title,\"img_url\":image_url}\n",
    "    \n",
    "    hemisphere_data.append(dictionary)\n",
    "    \n",
    "    browser.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hemisphere_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "0.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
